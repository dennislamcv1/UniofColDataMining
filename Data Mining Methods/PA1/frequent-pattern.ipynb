{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e413b24cf2f4ff97ee541826571fb8f",
     "grade": false,
     "grade_id": "cell-4e1696969eb81f75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Homework 1 -  Frequent Pattern Analysis\n",
    "***\n",
    "**Name**: $<$insert name here$>$ \n",
    "***\n",
    "\n",
    "Remember that you are encouraged to discuss the problems with your instructors and classmates, but **you must write all code and solutions on your own**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "859fb2ffd4d82989d0cbc1fa55ab8970",
     "grade": false,
     "grade_id": "cell-a0424d7dd292f236",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The rules to be followed for the assignment are:\n",
    "\n",
    "- Do **NOT** load additional packages beyond what we've shared in the cells below.\n",
    "- Some problems with code may be autograded.  If we provide a function or class API **do not** change it.\n",
    "- Do not change the location of the data or data directory.  Use only relative paths to access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85426c117172a12f69961fe44d5b76d3",
     "grade": false,
     "grade_id": "cell-208e6b52f66e263b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "import pickle5 as pickle\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "550feb4db919af7af5bd76039b77502b",
     "grade": false,
     "grade_id": "cell-41899a355c39fa18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [10 points] Problem 1 - Apriori Implementation\n",
    "***\n",
    "\n",
    "A sample dataset has been provided to you in the './data/dataset.pickle' path. Here are the attributes for the dataset. Use this dataset to test your functions.\n",
    "\n",
    "- Dataset should load the transactions in the form of a python dictionary where each key holds the transaction id and the value is a python list of the items purchased in that transaction. \n",
    "- An example transaction will have the following structure. If items A, C, D, F are purchased in transaction T3, this would appear as follows in the dictionary.\n",
    "\n",
    "```python\n",
    "transactions = {\n",
    "   \"T3\": [\"A\", \"C\", \"D\", \"F\"]\n",
    "}\n",
    "```\n",
    "\n",
    "Note:\n",
    "- A sample dataset to test your code has been provided in the location \"./data/dataset.pickle\". Please maintain this as it would be necessary while grading.\n",
    "- Do not change the variable names of the returned values.\n",
    "- After calculating each of those values, assign them to the corresponding value that is being returned.\n",
    "\n",
    "- If you are encountering any errors while loading the dataset, the following lines of code should help. Please delete the cells before submitting, to reduce any potential autograder issues.\n",
    "\n",
    "```python\n",
    "!pip install pickle5\n",
    "\n",
    "import pickle5 as pickle\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "  \n",
    "def findsubsets(s, n):\n",
    "    \n",
    "#   A helper function that you can use to list of all subsets of size n. Do not make any changes to this code block.\n",
    "#   Input: \n",
    "#       1. s - A python list of items\n",
    "#       2. n - Size of each subset\n",
    "#   Output:\n",
    "#       1. subsets - A python list containing the subsets of size n.\n",
    "    \n",
    "    subsets = list(sorted((itertools.combinations(s,n))))\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_from_frequent_itemsets(frequent_itemset):\n",
    "\n",
    "#   A helper function that you can use to get the sorted items from the frequent itemsets. Do not make any changes\n",
    "#   to this code block\n",
    "#   Input:\n",
    "#       1. Frequent Itemsets\n",
    "#   Output:\n",
    "#       1. Sorted list of items\n",
    "\n",
    "    items = list()\n",
    "    for keys in frequent_itemset.keys():\n",
    "        for item in list(keys):\n",
    "            items.append(item)\n",
    "    return sorted(list(set(items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c6a9b607de9874a42fa55da4dea5ed1",
     "grade": false,
     "grade_id": "cell-8aeecaf8c900b493",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_frequent_itemsets(dataset, support, items, n=1, frequent_items={}):\n",
    "    \n",
    "#   Input:\n",
    "#       1. dataset - A python dictionary containing the transactions.\n",
    "#       2. support - A floating point variable representing the min_support value for the set of transactions.\n",
    "#       3. items - A python list representing all the items that are part of all the transactions.\n",
    "#       4. n - An integer variable representing what frequent item pairs to generate.\n",
    "#       5. frequent_items - A dictionary representing k-1 frequent sets. \n",
    "#   Output:\n",
    "#       1. frequent_itemsets - A dictionary representing the frequent itemsets and their corresponding support counts.\n",
    "    \n",
    "    len_transactions = len(dataset)\n",
    "    frequent_itemsets = {}\n",
    "    \n",
    "    if n == 1: #Base case: scan dataset to generate frequent 1-itemsets\n",
    "        # your code here\n",
    "             \n",
    "        for item in items:\n",
    "            \n",
    "            n_item = 0\n",
    "            \n",
    "            for key in dataset.keys():\n",
    "                for i in range(len(dataset[key])):\n",
    "                    if dataset[key][i] == item:\n",
    "                        n_item = n_item + 1\n",
    "                        \n",
    "            prop_item = n_item / len(dataset.keys())\n",
    "            \n",
    "            if prop_item >= support:\n",
    "                frequent_itemsets.update({item: n_item})\n",
    "            \n",
    "            \n",
    "    else: #generate frequent k itemsets, knowing all frequent k-1 itemsets\n",
    "        \n",
    "        # your code here\n",
    "        assert len(frequent_items) != 0\n",
    "        \n",
    "        remaining_items = items_from_frequent_itemsets(frequent_items)\n",
    "        all_subsets = findsubsets(remaining_items, n)\n",
    "        \n",
    "        for subset in all_subsets:\n",
    "            n_subset = 0\n",
    "            \n",
    "            for transaction in dataset.keys():\n",
    "                in_transaction = True\n",
    "                for item in subset:\n",
    "                    if (item in dataset[transaction]) == False:\n",
    "                        in_transaction = False\n",
    "                        \n",
    "                if in_transaction:\n",
    "                    n_subset = n_subset + 1\n",
    "            \n",
    "            prop_subset = n_subset / len_transactions\n",
    "            \n",
    "            if prop_subset >= support:\n",
    "                frequent_itemsets.update({subset: n_subset})\n",
    "        \n",
    "        \n",
    "    return(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8eab04a351ad1812a95cd02b5e4a19b",
     "grade": true,
     "grade_id": "cell-9189aa11b7c2f094",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# This cell has hidden test cases that will run after you submit your assignment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 3, 'B': 5, 'D': 4}\n",
      "Test 1: frequent 1 itemsets\n",
      "{('A', 'B'): 3, ('B', 'D'): 4}\n",
      "Test 1: frequent 2 itemsets\n",
      "{}\n",
      "Test 1: frequent 3 itemsets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestX(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.min_support = 0.5\n",
    "        self.items = ['A', 'B', 'C', 'D', 'E']\n",
    "        self.dataset = dict()\n",
    "        self.dataset[\"T1\"] = ['A', 'B', 'D']\n",
    "        self.dataset[\"T2\"] = ['A', 'B', 'E']\n",
    "        self.dataset[\"T3\"] = ['B', 'C', 'D']\n",
    "        self.dataset[\"T4\"] = ['B', 'D', 'E']        \n",
    "        self.dataset[\"T5\"] = ['A', 'B', 'C', 'D']\n",
    "        \n",
    "    def test0(self):\n",
    "        frequent_1_itemsets = generate_frequent_itemsets(self.dataset, self.min_support, self.items)\n",
    "        print (frequent_1_itemsets)\n",
    "        frequent_1_itemsets_solution = dict()\n",
    "        frequent_1_itemsets_solution['A'] = 3\n",
    "        frequent_1_itemsets_solution['B'] = 5\n",
    "        frequent_1_itemsets_solution['D'] = 4\n",
    "\n",
    "        print (\"Test 1: frequent 1 itemsets\")\n",
    "        assert frequent_1_itemsets == frequent_1_itemsets_solution\n",
    "\n",
    "        frequent_2_itemsets = generate_frequent_itemsets(self.dataset, self.min_support, self.items, 2, frequent_1_itemsets)\n",
    "        print (frequent_2_itemsets)\n",
    "        frequent_2_itemsets_solution = dict()\n",
    "        frequent_2_itemsets_solution[('A', 'B')] = 3\n",
    "        frequent_2_itemsets_solution[('B', 'D')] = 4\n",
    "        \n",
    "        print (\"Test 1: frequent 2 itemsets\")\n",
    "        assert frequent_2_itemsets == frequent_2_itemsets_solution\n",
    "\n",
    "        frequent_3_itemsets = generate_frequent_itemsets(self.dataset, self.min_support, self.items, 3, frequent_2_itemsets)\n",
    "        print (frequent_3_itemsets)\n",
    "        frequent_3_itemsets_solution = dict()\n",
    "\n",
    "        print (\"Test 1: frequent 3 itemsets\")\n",
    "        assert frequent_3_itemsets == frequent_3_itemsets_solution         \n",
    "   \n",
    "tests = TestX()\n",
    "tests_to_run = unittest.TestLoader().loadTestsFromModule(tests)\n",
    "unittest.TextTestRunner().run(tests_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10 points] Problem 2 - FP-Growth Implementation\n",
    "***\n",
    "\n",
    "A sample dataset has been provided to you in the './data/dataset.pickle' path. Here are the attributes for the dataset. Use this dataset to test your functions.\n",
    "\n",
    "- Dataset should load the transactions in the form of a python dictionary where each key holds the transaction id and the value is a python list of the items purchased in that transaction. \n",
    "- An example transaction will have the following structure. If items A, C, D, F are purchased in transaction T3, this would appear as follows in the dictionary.\n",
    "\n",
    "```python\n",
    "transactions = {\n",
    "   \"T3\": [\"A\", \"C\", \"D\", \"F\"]\n",
    "}\n",
    "```\n",
    "\n",
    "Note:\n",
    "- A sample dataset to test your code has been provided in the location \"./data/dataset.pickle\". Please maintain this as it would be necessary while grading.\n",
    "- Do not change the variable names of the returned values.\n",
    "- After calculating each of those values, assign them to the corresponding value that is being returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "203c4e5353d0b261f7d8eec326a15bd0",
     "grade": false,
     "grade_id": "cell-044bd5cae7c41526",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def item_support(dataset, min_support):\n",
    "    \n",
    "#   A helper function that returns the support count of each item in the dataset.\n",
    "#   Input:\n",
    "#       1. dataset - A python dictionary containing the transactions. \n",
    "#       2. min_support - A floating point variable representing the min_support value for the set of transactions.\n",
    "#   Output:\n",
    "#       1. support_dict - A dictionary representing the support count of each item in the dataset.\n",
    "    \n",
    "    len_transactions = len(dataset)\n",
    "    support_dict = defaultdict(int)\n",
    "    \n",
    "    for transaction in dataset.values():\n",
    "        for item in transaction:\n",
    "            support_dict[item] += 1\n",
    "    \n",
    "    # Filter items by min_support\n",
    "    sorted_support = dict(sorted(support_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    pruned_support = {key: val for key, val in sorted_support.items() if val / len_transactions >= min_support}\n",
    "    \n",
    "    return pruned_support    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "344f60e12f23493fc48a2c10eff9216d",
     "grade": false,
     "grade_id": "cell-28a862623c5f9f42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected support_dict value for the given dataset is: {'C': 7, 'D': 9, 'E': 5, 'B': 6, 'A': 6}\n",
      "Your support_dict value is: {'D': 9, 'C': 7, 'B': 6, 'A': 6, 'E': 5}\n",
      "Visible tests passed!\n"
     ]
    }
   ],
   "source": [
    "# This cell has visible test cases that you can run to see if you are on the right track!\n",
    "# Note: hidden tests will also be applied on other datasets for final grading.\n",
    "\n",
    "dataset = dict()\n",
    "with open('./data/dataset.pickle', 'rb') as handle:\n",
    "    dataset = pickle.load(handle)\n",
    "\n",
    "support_dict = item_support(dataset, 0.5)\n",
    "support_dict_expected = {'C': 7, 'D': 9, 'E': 5, 'B': 6, 'A': 6}\n",
    "\n",
    "print(f'The expected support_dict value for the given dataset is: {support_dict_expected}')\n",
    "print(f'Your support_dict value is: {support_dict}')\n",
    "\n",
    "try:\n",
    "    assert support_dict == support_dict_expected\n",
    "    print(\"Visible tests passed!\")\n",
    "except:\n",
    "    print(\"Visible tests failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01c2205b421f343b2900235853035d64",
     "grade": true,
     "grade_id": "cell-330eca95a174c213",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# This cell has hidden test cases that will run after you submit your assignment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9faf8566119f9053cd938aa7a601245",
     "grade": false,
     "grade_id": "cell-94f1180e7b0df5fe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def reorder_transactions(dataset, min_support):\n",
    "    \n",
    "#   A helper function that reorders the transaction items based on maximum support count. It is important that you finish\n",
    "#   the code in the previous cells since this function makes use of the support count dictionary calculated above.\n",
    "#   Input:\n",
    "#       1. dataset - A python dictionary containing the transactions. \n",
    "#       2. min_support - A floating point variable representing the min_support value for the set of transactions.\n",
    "#   Output:\n",
    "#       1. updated_dataset - A dictionary representing the transaction items in sorted order of their support counts.\n",
    "\n",
    "    pruned_support = item_support(dataset, min_support) \n",
    "    updated_dataset = dict()\n",
    "    \n",
    "    # This loop sorts the transaction items based on the item support counts\n",
    "    for key, value in dataset.items():\n",
    "        updated_dataset[key] = sorted(value, key=pruned_support.get, reverse=True)\n",
    "    \n",
    "    # Update the following loop to remove items that do not belong to the pruned_support dictionary\n",
    "    for key, value in updated_dataset.items():\n",
    "        updated_values = [item for item in value if item in pruned_support]\n",
    "        updated_dataset[key] = updated_values\n",
    "\n",
    "    return updated_dataset\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b36eec55154d7d160f3766bc20649d16",
     "grade": false,
     "grade_id": "cell-8b9d589cb8cb707e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected updated_dataset value for the given dataset is:\n",
      "{'T1': ['D', 'C', 'E'],\n",
      " 'T10': ['D', 'C', 'A', 'B', 'E'],\n",
      " 'T2': ['D', 'C', 'B'],\n",
      " 'T3': ['D', 'C', 'A'],\n",
      " 'T4': ['D', 'C', 'A', 'E'],\n",
      " 'T5': ['D', 'C', 'A', 'B'],\n",
      " 'T6': ['B'],\n",
      " 'T7': ['D', 'E'],\n",
      " 'T8': ['D', 'C', 'A', 'B'],\n",
      " 'T9': ['D', 'A', 'B', 'E']}\n",
      "Your updated_dataset value is:\n",
      "{'T1': ['D', 'C', 'E'],\n",
      " 'T10': ['D', 'C', 'A', 'B', 'E'],\n",
      " 'T2': ['D', 'C', 'B'],\n",
      " 'T3': ['D', 'C', 'A'],\n",
      " 'T4': ['D', 'C', 'A', 'E'],\n",
      " 'T5': ['D', 'C', 'A', 'B'],\n",
      " 'T6': ['B'],\n",
      " 'T7': ['D', 'E'],\n",
      " 'T8': ['D', 'C', 'A', 'B'],\n",
      " 'T9': ['D', 'A', 'B', 'E']}\n",
      "Visible tests passed!\n"
     ]
    }
   ],
   "source": [
    "# This cell has visible test cases that you can run to see if you are on the right track!\n",
    "# Note: hidden tests will also be applied on other datasets for final grading.\n",
    "\n",
    "import pprint\n",
    "import json\n",
    "pp = pprint.PrettyPrinter(depth=4)\n",
    "\n",
    "dataset = dict()\n",
    "with open('./data/dataset.pickle', 'rb') as handle:\n",
    "    dataset = pickle.load(handle)\n",
    "\n",
    "updated_dataset = reorder_transactions(dataset, 0.5)\n",
    "updated_dataset_expected = {'T1': ['D', 'C', 'E'], 'T2': ['D', 'C', 'B'], 'T3': ['D', 'C', 'A'],\n",
    "                            'T4': ['D', 'C', 'A', 'E'], 'T5': ['D', 'C', 'A', 'B'], 'T6': ['B'],\n",
    "                            'T7': ['D', 'E'], 'T8': ['D', 'C', 'A', 'B'], 'T9': ['D', 'A', 'B', 'E'], 'T10': ['D', 'C', 'A', 'B', 'E']}\n",
    "\n",
    "print(f'The expected updated_dataset value for the given dataset is:')\n",
    "pp.pprint(updated_dataset_expected)\n",
    "print(f'Your updated_dataset value is:')\n",
    "pp.pprint(updated_dataset)\n",
    "\n",
    "try:\n",
    "    assert updated_dataset == updated_dataset_expected\n",
    "    print(\"Visible tests passed!\")\n",
    "except:\n",
    "    print(\"Visible tests failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "625f269cce0dc5754fac52ea5557bb63",
     "grade": true,
     "grade_id": "cell-f75886c98dbd692b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# This cell has hidden test cases that will run after you submit your assignment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bcd039f72cfadd9a9875f3bf12015b66",
     "grade": false,
     "grade_id": "cell-d8903df190fbb499",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def build_fp_tree(updated_dataset):\n",
    "    \n",
    "#   Input: \n",
    "#       1. updated_dataset - A python dictionary containing the updated set of transactions based on the pruned support dictionary.\n",
    "#   Output:\n",
    "#       1. fp_tree - A dictionary representing the fp_tree. Each node should have a count and children attribute.\n",
    "#        \n",
    "#   HINT:\n",
    "#       1. Loop over each transaction in the dataset and make an update to the fp_tree dictionary. \n",
    "#       2. For each loop iteration store a pointer to the previously visited node and update it's children in the next pass.\n",
    "#       3. Update the root pointer when you start processing items in each transaction.\n",
    "#       4. Reset the root pointer for each transaction.\n",
    "#\n",
    "#   Sample Tree Output:\n",
    "#   {'Y': {'count': 3, 'children': {'V': {'count': 1, 'children': {}}}},\n",
    "#    'X': {'count': 2, 'children': {'R': {'count': 1, 'children': {'F': {'count': 1, 'children': {}}}}}}}\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    fp_tree = {}\n",
    "\n",
    "    for transaction in updated_dataset.values():\n",
    "        current_node = fp_tree\n",
    "        for item in transaction:\n",
    "            if item in current_node:\n",
    "                current_node[item]['count'] += 1\n",
    "            else:\n",
    "                current_node[item] = {'count': 1, 'children': {}}\n",
    "            current_node = current_node[item]['children']\n",
    "    \n",
    "    return fp_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "588eac71887654aece522c41278b046f",
     "grade": false,
     "grade_id": "cell-be66db688dcf72ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected fp_tree value for the given dataset is:\n",
      "{'B': {'children': {}, 'count': 1},\n",
      " 'D': {'children': {'A': {'children': {'B': {'children': {'E': {'children': {},\n",
      "                                                                'count': 1}},\n",
      "                                             'count': 1}},\n",
      "                          'count': 1},\n",
      "                    'C': {'children': {'A': {'children': {'B': {'children': {'E': {'children': {},\n",
      "                                                                                   'count': 1}},\n",
      "                                                                'count': 3},\n",
      "                                                          'E': {'children': {},\n",
      "                                                                'count': 1}},\n",
      "                                             'count': 5},\n",
      "                                       'B': {'children': {}, 'count': 1},\n",
      "                                       'E': {'children': {}, 'count': 1}},\n",
      "                          'count': 7},\n",
      "                    'E': {'children': {}, 'count': 1}},\n",
      "       'count': 9}}\n",
      "\n",
      "Your fp_tree value is:\n",
      "{'B': {'children': {}, 'count': 1},\n",
      " 'D': {'children': {'A': {'children': {'B': {'children': {'E': {'children': {},\n",
      "                                                                'count': 1}},\n",
      "                                             'count': 1}},\n",
      "                          'count': 1},\n",
      "                    'C': {'children': {'A': {'children': {'B': {'children': {'E': {'children': {},\n",
      "                                                                                   'count': 1}},\n",
      "                                                                'count': 3},\n",
      "                                                          'E': {'children': {},\n",
      "                                                                'count': 1}},\n",
      "                                             'count': 5},\n",
      "                                       'B': {'children': {}, 'count': 1},\n",
      "                                       'E': {'children': {}, 'count': 1}},\n",
      "                          'count': 7},\n",
      "                    'E': {'children': {}, 'count': 1}},\n",
      "       'count': 9}}\n",
      "Visible tests passed!\n"
     ]
    }
   ],
   "source": [
    "# This cell has visible test cases that you can run to see if you are on the right track!\n",
    "# Note: hidden tests will also be applied on other datasets for final grading.\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(depth=8)\n",
    "\n",
    "dataset = dict()\n",
    "with open('./data/dataset.pickle', 'rb') as handle:\n",
    "    dataset = pickle.load(handle)\n",
    "\n",
    "updated_dataset = reorder_transactions(dataset, 0.5)\n",
    "\n",
    "fp_tree = build_fp_tree(updated_dataset)\n",
    "fp_tree_expected = {'D': {'count': 9,\n",
    "  'children': {'C': {'count': 7,\n",
    "    'children': {'E': {'count': 1, 'children': {}},\n",
    "     'B': {'count': 1, 'children': {}},\n",
    "     'A': {'count': 5,\n",
    "      'children': {'E': {'count': 1, 'children': {}},\n",
    "       'B': {'count': 3, 'children': {'E': {'count': 1, 'children': {}}}}}}}},\n",
    "   'E': {'count': 1, 'children': {}},\n",
    "   'A': {'count': 1,\n",
    "    'children': {'B': {'count': 1,\n",
    "      'children': {'E': {'count': 1, 'children': {}}}}}}}},\n",
    " 'B': {'count': 1, 'children': {}}}\n",
    "\n",
    "print(f'The expected fp_tree value for the given dataset is:')\n",
    "pp.pprint(fp_tree_expected)\n",
    "print(f'\\nYour fp_tree value is:')\n",
    "pp.pprint(fp_tree)\n",
    "\n",
    "try:\n",
    "    assert fp_tree == fp_tree_expected\n",
    "    print(\"Visible tests passed!\")\n",
    "except:\n",
    "    print(\"Visible tests failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c865a0c008a30070a43f46bc32f4b0f1",
     "grade": true,
     "grade_id": "cell-2e8a2c6ab7c275e5",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# This cell has hidden test cases that will run after you submit your assignment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
